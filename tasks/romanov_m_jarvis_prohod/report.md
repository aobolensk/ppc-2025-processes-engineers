# Построение выпуклой оболочки – проход Джарвиса.

- Студент: Романов Михаил Павлович, группа 3823Б1ПР4
- Технология: SEQ | MPI
- Вариант: 25

## 1. Введение

Задача построения выпуклой оболочки широко используется в вычислительной геометрии, но что выпуклая оболочка из себя представляет? Выпуклая оболочка - это минимальный выпуклый многоугольник, который содержит все точки множества. Выпуклая оболочка также используется в компьютерной графике, обработке изображений и т.д.

При больших объёмах данных и необходимости ускорения вычислений используется параллельное программирование с помощью MPI, позволяющее распределить обработку по нескольким процессам.

## 2. Постановка задачи

Дано множество точек, которые находятся на плоскости, нужно построить выпуклую оболочку этих точек. Реализовано это будет с помощью прохода джарвиса.
**Входные данные:** Вектор точек, каждая с координатами (x,y).
**Выходные данные** Вектор точек, который образует вершины оболочки в порядке обхода.

## 3. Базовый алгоритм (Последовательный)

Использован классический алгоритм Джарвиса (Jarvis March), основанный на обходе внешних точек:

1.Найти левую нижнюю точку — стартовую вершину оболочки.

2.Итеративно выбирать следующую точку, такую что все остальные точки лежат справа от направления к ней (используется знак векторного произведения).

3.В случае коллинеарности выбирается самая удалённая точка.

4.Продолжать, пока не вернёмся к начальной точке.

## 4. Параллелизация

В отличии от последовательной версии, параллельная решает задачу, распределяя точки по процессам:
Входные данные делятся равномерно с помощью MPI_Scatterv между процессами.

Каждый процесс вычисляет выпуклую оболочку своего подмножества точек.

Все локальные оболочки собираются на корневом процессе с помощью MPI_Gatherv.

На корневом процессе объединённый набор точек обрабатывается последовательным алгоритмом для получения итоговой оболочки.

Итоговая оболочка распространяется всем процессам через MPI_Bcast.

## 5. Детали реализации
Для MPI создан собственный тип данных MPI_Datatype для структур Point.

Распределение данных учитывает остаток от деления для равномерности.

Используется синхронизация и коллективные операции MPI.

Для проверки корректности использованы функциональные и производительные тесты.

## 6. Тестовое окружение
* Аппаратное обеспечение/Операционная система: AMD Ryzen 5 7640HS, 6 ядер/12 потоков, LPDDR5X 16 GB, Windows 11.
* Инструменты сборки: Visual studio 2022 community release. CMake 4.2.0.
* Переменные окружения: PPC_NUM_THREADS=PPC_NUM_PROC=1/2/4/6/8/12/16, PPC_PERF_MAX_TIME=10000.
* Данные:  размер входного массива до 10000000 точек (для тестов)

## 7. Результаты

### 7.1 Корректность
Корректность проверялась с использованием набора функциональных тестов, включая:

Результаты параллельной версии (MPI) полностью совпали с результатами последовательной (SEQ) реализации для всех тестовых случаев.
### 7.2 Производительность
|Режим|Число процессов|Время(мс)|Ускорение|Эффективность|
|-----|---------------|---------|---------|-|
|seq|1|390|1||
|mpi|4|347|1.124|28.1%|
|mpi|8|427|0.913|11.4%|
|mpi|12|570|0.684|5.7%|
|mpi|16|581|0.671|4.2%|

Алгоритм демонстрирует ускорение в 0.671 с 16 процессами по сравнение с 1. На протяжение увеличения процессов идёт линейное падение ускорения.

P=4 наблюдается прирост. Эффективность крайне низкая, вероятно это связано с техническами характеристиками(недостаточным количеством ядер), т.к при четырёх процессах прирост наблюдается, а при 8 уже нет, а ядер всего 6.

### 8. Заключение
Разработана последовательная и параллельная MPI-реализация алгоритма Джарвиса для нахождения выпуклой оболочки множества точек. Корректность подтверждена функциональными тестами. Параллельная версия позволяет ускорить обработку, но только при 4 процессах и не сильно за счёт распределения данных, однако производительность при увелечении процессов падает, вероятно если проверять на устройстве с большим количеством ядер, то результат будет другим.

### 9. Источники

1.  Microsoft MPI : документация [Электронный ресурс] // Microsoft Learn. – URL: https://learn.microsoft.com/ru-ru/message-passing-interface/microsoft-mpi
2. Сысоев А. В. Курс лекций по параллельному программированию.
3. Parallel programming course [Электронный ресурс] : документация URL: https://learning-process.github.io/parallel_programming_course/ru/common_information/processes_tasks.html
4. Построение минимальных выпуклых оболочек - статья хабр: https://habr.com/ru/articles/144921/?ysclid=mjfov2tqx8340615102
5. Алгоритм Джарвиса: https://ru.ruwiki.ru/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%94%D0%B6%D0%B0%D1%80%D0%B2%D0%B8%D1%81%D0%B0